16.02
- Got my desk
- Went to Weissach to setup the hardware on the car.
- Came back
- Read some papers about sensor fusion.
- Learnt about Data Loader for PyTorch.



- Tried to obtain admin rights. Submitted ticket for it.
- Downloaded Veloview to visualize velodyne lidar.
- Learnt about Lidar.
- Installed PyTorch and VSC.

18.02
- Learnt in depth about OOPs.
- Did iPhone software update.

19.02
- Unboxed the Hesai Lidar
- Tried installing Pandarview but cannot due to no admin rights.
- Using Open3D to visualize the Point Clouds but could not connect lidar to system.
- Finally figured out the proxy stuff by downloading the .pip file.

20.02
- Read Research papers about fusion
- Researched about camera calibration

21.02
- Went to Weissach to install the sensors on the test car.
- Drove around in Weissach campus to record the data.

22,23 - Weekend+

24.02
- Installed Nvidia CUDA Toolkit on Ubuntu Laptop and did troubleshooting as nvidia-smi was not working. Fixed it by disabling fast boot.
- Installed PandarView and recorded some Lidar data inside the office.

25.02
- Will view the data with ROS2 in the docker container on my laptop.
- Installed nvidia driver 550
- Installed CUDA Toolkit 12.4
- Installed ROS2 on my laptop
- Learnt some Linux commands

26.02 
- Understood in depth about camera calibration
- Studied some ROS2 concepts
- Wanted to fix errors with ROS2 but could not as I had forgotten my charger at home.

5.03 
- Understood lidar calibration
- Solved no GUI problem in Ubuntu with the command sudo systemctl restart gdm
- Connected to the wifi using the terminal using the command nmcli dev wifi connect 'Name' 'Password'
- Found out that there are three potential methods to create dense depth maps.  Either very costly lidar, using stereo cameras  or multiple frames SLAM. The third option seems more viable.

6.03
- Understood how exactly depth cameras work
- Created depth map from a KITTI Dataset sample
- Understood how transformation matrix works
- Learned to read the intrinsic matrix and translation coefficients.

7.03 
- Learned a method called multi frame using Lidar.
- The idea is to create a world frame to avoid merging point clouds for varying sizes.
- Had a quick meeting with my professor regarding our kick-off meeting.

10.03
- Understood what rotation matrix really does.
- Ask Gasser why the Z component of the translation matrix is negative.
- Finally projected lidar point clouds on the stereo camera images. The trick was to use the R_rect02 matrix of the camera 02 and the projection matrix.


11.03
- Created a depth map from stereo image using SGM

12.03
- Created a depth map using lidar point clouds using bilateral filtering and linear interpolation.
- For the points which are too away from the existing points, used the method 'nearest points'
- Downloaded GitKraken and created a repo on GitHub using my work email.

13.03
- Read about Foundation Stereo
- Placed request for proxy
- Placed ticket for admin rights

14.03 
- Tried to implement FoundationStereo

17.03
- Finally implemented FoundationStereo, the trick was to disable GPU and use CPU and disable flash attention. Achieved dense depth map and point clouds from stereo image pair.

18.03
- Learnt about Git commands. Went to Weissach to mount the sensors on the car. 

19.03
- Did interpolation with nearest neighbor and OpenCV's inpaint.

20.03
- Talked to the professor regarding professor.
- Understood the overall goal. The dense depth lidar maps will be provided by a company. We have to compare the accuracy of the predicted depth map using that ground truth.

21.03

- Downloaded a repo to blur faces and number plates of a car.

24.03
- Found what was the issue in FS. Converted the disparities to depths.

25.03

- Tried DepthPro, another repo which deals with depth estimation.
- Will create my own script which uses the FoundationStereo Model

26.03
- Finally achieved an acceptable result with FS. The problem was, I was not using the vmin and vmax parameters while visualizing the depths. Thats why all pixels were yellow.
- Will test the anomyser git repo on multiple cases.
- Will compute the median of the GT in distances from 0 to 80 meters.

27.03 

- Obtained the perfect result with FS. The solution was to use the correct intrinsic matrix which is the projection matrix.

01.04
- Created anomyser pipeline which takes in photos and anomyses them.

02.04

- Read the paper 'Real-time depth completion based on LiDAR-stereo for autonomous driving' and did its lit review.
- Tried searching models for potholes and other road anomalities for automatic labelling of them on photos.

03.04
 - Explored the dataset recorded by Gasser. Learned about .las and .laz files. Obtained the calibration information.
 - Downloaded Cloud Compare to view .las files.
 - Did not work. So downloaded LASTools to convert .laz to .las and then viewed the point clouds using Open3D.

04.04
 - Understood the architecture of the camera files and point clouds. 
 - Will project the point clouds on the camera image today and compare with FoundationStereo

07.04 
 - Solved the proxy issue and did pip setup

10.04
 - Finally projected the point clouds on the camera images. The idea was to first convert the points from world to rig system and then to camera.

14.04
 - Will use an automated annotation tool to annotate images.

16.04
- Testing of the automated tool on a sample dataset.
- Gaining access to the workstation with Gasser.

17.04
- 12 Years of best birthday ever.
- Annotated 140 images comprising of potholes and drainage holes.
- Tried training a TF model on that data but faced issues with dependencies.

22.04
- Got access to the workstation, have raised a ticket for SSH
- Ran the Anomyzer on all images from sw folder.
- Got a script from Gasser which aggregates the point clouds from multiple frames.
- Have to deploy FS on the frame and compare with the dense point clouds.

23.04
- Got access to SSH
- Tried to run FS on my laptop but my CPU is too weak. Will run everything on the Workstation now.
- Have created a script which integrates FoundationStereo with the Lidar point projection.

24.94
 - Tried to use FoundationStereo but got CUDA memory errors.

25.04
 - Installed CUDA toolkit without sudo.
 - Installed flash_attn
 - Managed to run foundation stereo by resizing images and other fixes by Gasser.
 - Calculated Errors between GT and FS on one frame. The error is around 20 meters.

28.04 - 30.04
 - Tried improving FS by applying rectification by OpenCV tools.
 - Found out that there is some issue with calibration.
 - Was going to record more data but the sensor setup was damaged due to not considering the height of the parking lot.

02.05
 - Will plot the point clouds on a KITTI dataset image and then check if FS works well.
 - KITTI works really work on FS. The FS point clouds and GT overlapped very well.
 - Using scaling of 2 and rectification intrinsics, the medians were very close now.
 - Trained a simple PyTorch model to predict road profiles on just 101 images.

05.05
 - Decided to use Yolov8 model for irregularities detection.
 - Trained a model on the same dataset as before and obtained better results.
 - Installed labelImg on workstation for labeling.
 - Went to workstation and used the wlan adapter to fix the mounting of dataset.

06.05
 - Created a script which takes 50 random images from a sample for annotation.
 - Will grab 50 images from each folder to create a big dataset for annotation.
 - Labelled images from day 1 data using labelimg and trained a yolo model.

07.05
 - Trained a model on day 1 and day 2 data and saw improved results
 - Had a meet with the professor regarding the progress and sent him the outputs of the anonymizer tool

08.05
 - Read a research paper "Dynamic Spatial Propagation Network for Depth Completion" given by gasser

09.05
 - Got more data from day_1 recordings and trained a model. mAp reached 0.7
 - Integrated the rectification script given by Gasser.

12.05 
 - Used UniDepth to find out depths and point clouds.
 
13.05
 - Used DepthPro and UniDepth to find out depths and point clouds on own data
 - Programmed scripts in these two models to use own instrincs as well as predicted intrinsics.

19.05
 - Created three crucial scripts to rectify images, run foundationstereo on the rectified pair, edited the script which creates ground truth and created an evaluation script for the point clouds.
 - Tested the scripts on new intrinsics and the results are insanely better than before
 - 