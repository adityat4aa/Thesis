16.02
- Got my desk
- Went to Weissach to setup the hardware on the car.
- Came back
- Read some papers about sensor fusion.
- Learnt about Data Loader for PyTorch.



- Tried to obtain admin rights. Submitted ticket for it.
- Downloaded Veloview to visualize velodyne lidar.
- Learnt about Lidar.
- Installed PyTorch and VSC.

18.02
- Learnt in depth about OOPs.
- Did iPhone software update.

19.02
- Unboxed the Hesai Lidar
- Tried installing Pandarview but cannot due to no admin rights.
- Using Open3D to visualize the Point Clouds but could not connect lidar to system.
- Finally figured out the proxy stuff by downloading the .pip file.

20.02
- Read Research papers about fusion
- Researched about camera calibration

21.02
- Went to Weissach to install the sensors on the test car.
- Drove around in Weissach campus to record the data.

22,23 - Weekend+

24.02
- Installed Nvidia CUDA Toolkit on Ubuntu Laptop and did troubleshooting as nvidia-smi was not working. Fixed it by disabling fast boot.
- Installed PandarView and recorded some Lidar data inside the office.

25.02
- Will view the data with ROS2 in the docker container on my laptop.
- Installed nvidia driver 550
- Installed CUDA Toolkit 12.4
- Installed ROS2 on my laptop
- Learnt some Linux commands

26.02 
- Understood in depth about camera calibration
- Studied some ROS2 concepts
- Wanted to fix errors with ROS2 but could not as I had forgotten my charger at home.

5.03 
- Understood lidar calibration
- Solved no GUI problem in Ubuntu with the command sudo systemctl restart gdm
- Connected to the wifi using the terminal using the command nmcli dev wifi connect 'Name' 'Password'
- Found out that there are three potential methods to create dense depth maps.  Either very costly lidar, using stereo cameras  or multiple frames SLAM. The third option seems more viable.

6.03
- Understood how exactly depth cameras work
- Created depth map from a KITTI Dataset sample
- Understood how transformation matrix works
- Learned to read the intrinsic matrix and translation coefficients.

7.03 
- Learned a method called multi frame using Lidar.
- The idea is to create a world frame to avoid merging point clouds for varying sizes.
- Had a quick meeting with my professor regarding our kick-off meeting.

10.03
- Understood what rotation matrix really does.
- Ask Gasser why the Z component of the translation matrix is negative.
- Finally projected lidar point clouds on the stereo camera images. The trick was to use the R_rect02 matrix of the camera 02 and the projection matrix.


11.03
- Created a depth map from stereo image using SGM

12.03
- Created a depth map using lidar point clouds using bilateral filtering and linear interpolation.
- For the points which are too away from the existing points, used the method 'nearest points'
- Downloaded GitKraken and created a repo on GitHub using my work email.

13.03
- Read about Foundation Stereo
- Placed request for proxy
- Placed ticket for admin rights

14.03 
- Tried to implement FoundationStereo

17.03
- Finally implemented FoundationStereo, the trick was to disable GPU and use CPU and disable flash attention. Achieved dense depth map and point clouds from stereo image pair.

18.03
- Learnt about Git commands. Went to Weissach to mount the sensors on the car. 

19.03
- 
